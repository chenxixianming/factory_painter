import cv2
import os
import numpy as np
import json
from ocr_utils import IndustrialOCRManager
from sam2_utils import SAM2Segmenter

# --- 1. é…ç½®è·¯å¾„ ---
img_name = "map_8.png"
img_path = os.path.join("data", img_name)
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# --- 2. åˆå§‹åŒ–ä¸¤å¤§å¼•æ“ (åªåšä¸€æ¬¡) ---
ocr_manager = IndustrialOCRManager()
# sam2_engine = SAM2Segmenter(model_type="tiny")

# --- 3. ä¸€é”®è·å– OCR åˆå¹¶ç»“æœ ---
texts, centers, boxes = ocr_manager.get_merged_results(img_path)

ocr_data = []
for i in range(len(texts)):
    ocr_data.append({
        "id": i,
        "text": texts[i],
        "center": [float(centers[i][0]), float(centers[i][1])], # ç¡®ä¿æ˜¯ float
        "box": [float(boxes[i][0]), float(boxes[i][1]), float(boxes[i][2]), float(boxes[i][3])]
    })

# ä¿å­˜ä¸º JSON æ–‡ä»¶
json_path = os.path.join(output_dir, f"{img_name}.json")
with open(json_path, 'w', encoding='utf-8') as f:
    json.dump(ocr_data, f, ensure_ascii=False, indent=4)

print(f"âœ… OCR ç»“æœå·²ä¿å­˜è‡³: {json_path}")


json_path = os.path.join("output", f"{img_name}.json")
with open(json_path, 'r', encoding='utf-8') as f:
    ocr_results = json.load(f)

boxes = [item["box"] for item in ocr_results]

if not boxes:
    print("JSON ä¸­æ²¡æœ‰æ‰¾åˆ° Box æ•°æ®")
    exit()

# 2. åˆå§‹åŒ– SAM 2
sam2 = SAM2Segmenter(model_type="tiny")



#-----------------------------------------------
#å»é™¤æ–‡å­—
#-----------------------------------------------

# 3. è¯»å–å›¾åƒ
image_bgr = cv2.imread(img_path)
image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
color_overlay = image_bgr.copy()

# 4. ã€æ ¸å¿ƒè°ƒç”¨ã€‘æ‰¹é‡è·å–æ‰€æœ‰ Masks
# è¿™ä¸€æ­¥éå¸¸å¿«ï¼Œå› ä¸ºæ˜¯ä¸€æ¬¡æ€§æ¨ç†
print(f"æ­£åœ¨ä¸º {len(boxes)} ä¸ªåŒºåŸŸç”Ÿæˆæ©ç ...")
all_masks = sam2.get_masks_by_boxes(image_rgb, boxes)

# 5. éå† Mask è¿›è¡Œä¸Šè‰²
for i, mask in enumerate(all_masks):
    # mask å·²ç»æ˜¯ (H, W) çš„å¸ƒå°”æˆ– 0/1 çŸ©é˜µ
    mask_bool = mask.astype(bool)
    
    # éšæœºé¢œè‰²
    # color = np.random.randint(0, 255, (3,)).tolist()
    color = [255, 255, 255]
    
    # ä¸Šè‰²
    color_overlay[mask_bool] = color
    
    # æ‰“å°å¯¹åº”çš„æ–‡å­—ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
    print(f"å·²å¤„ç†: {ocr_data[i]['text']}")

# 6. ä¿å­˜ç»“æœ
result = cv2.addWeighted(image_bgr, 0.7, color_overlay, 0.3, 0)
save_path = os.path.join("output", f"sam2_box_whight_colored_{img_name}")
# cv2.imwrite(save_path, result)
cv2.imwrite(save_path, color_overlay)
print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {save_path}")




#-----------------------------------------------
#SAMåœ¨å»é™¤æ–‡å­—çš„å›¾ä¸Šåˆ†åŒº
#-----------------------------------------------

centers = [item["center"] for item in ocr_results]

# # --- 4. SAM2 åˆ†åŒºä¸Šè‰² ---
sam2_engine = SAM2Segmenter(model_type="tiny")
image_bgr = color_overlay
image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
color_overlay = image_bgr.copy()

all_masks = sam2.get_mask_by_point(image_rgb, centers)

sam2_engine.predictor.set_image(image_rgb)

# --- 2. éå† JSON æ•°æ®è¿›è¡Œä¸Šè‰² ---
for item in ocr_results:
    text = item["text"]
    center = item["center"] # [x, y]
    
    # è§£å†³â€œåªæ¶‚æ–‡å­—â€çš„å…³é”®ç‚¹ï¼šä½¿ç”¨å¤šæ©ç è¾“å‡ºå¹¶é€‰æ‹©æœ€å¤§èŒƒå›´
    masks, scores, _ = sam2_engine.predictor.predict(
        point_coords=np.array([center]),
        point_labels=np.array([1]),
        multimask_output=True # å¿…é¡»ä¸º True
    )
    
    # é€‰æ‹©å¾—åˆ†æœ€é«˜æˆ–èŒƒå›´æœ€å¹¿çš„ mask (é€šå¸¸ masks[2] èŒƒå›´æœ€å¤§)
    # ä½ å¯ä»¥æ ¹æ®å®é™…æ•ˆæœå°è¯• masks[np.argmax(scores)] æˆ–å›ºå®š masks[1]
    best_mask = masks[np.argmax(scores)].astype(bool)
    
    # éšæœºé¢œè‰²å¹¶ä¸Šè‰²
    color = np.random.randint(0, 255, (3,)).tolist()
    color_overlay[best_mask] = color
    print(f"å·²ä» JSON è¯»å–å¹¶ä¸Šè‰²: {text}")

# --- 3. åˆæˆä¿å­˜ ---
final_res = cv2.addWeighted(image_bgr, 0.7, color_overlay, 0.3, 0)
cv2.imwrite(os.path.join("output", f"point_colored_{img_name}"), final_res)

# for i, mask in enumerate(all_masks):
#     # mask å·²ç»æ˜¯ (H, W) çš„å¸ƒå°”æˆ– 0/1 çŸ©é˜µ
#     mask_bool = mask.astype(bool)
    
#     # éšæœºé¢œè‰²
#     color = np.random.randint(0, 255, (3,)).tolist()
#     # color = [255, 255, 255]
    
#     # ä¸Šè‰²
#     color_overlay[mask_bool] = color
    
#     # æ‰“å°å¯¹åº”çš„æ–‡å­—ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
#     print(f"å·²å¤„ç†: {ocr_data[i]['text']}")

# # 6. ä¿å­˜ç»“æœ
# result = cv2.addWeighted(image_bgr, 0.7, color_overlay, 0.3, 0)
# save_path = os.path.join("output", f"sam2_point_colored_{img_name}")
# # cv2.imwrite(save_path, result)
# cv2.imwrite(save_path, result)
# print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {save_path}")

# print("å¼€å§‹åˆ†åŒºä¸Šè‰²...")
# for item in ocr_results:
#     text = item["text"]
#     center = item["center"] # [x, y]
#     box = item["box"]
    
#     # è§£å†³â€œåªæ¶‚æ–‡å­—â€çš„å…³é”®ç‚¹ï¼šä½¿ç”¨å¤šæ©ç è¾“å‡ºå¹¶é€‰æ‹©æœ€å¤§èŒƒå›´
#     masks, scores, _ = sam2_engine.predictor.predict(
#         point_coords=np.array([center]),
#         point_labels=np.array([2]),
#         box = 
#         multimask_output=False # å¿…é¡»ä¸º True
#     )
    
#     # é€‰æ‹©å¾—åˆ†æœ€é«˜æˆ–èŒƒå›´æœ€å¹¿çš„ mask (é€šå¸¸ masks[2] èŒƒå›´æœ€å¤§)
#     # ä½ å¯ä»¥æ ¹æ®å®é™…æ•ˆæœå°è¯• masks[np.argmax(scores)] æˆ–å›ºå®š masks[1]
#     # best_mask = masks[np.argmax(scores)].astype(bool)
#     best_mask = masks[0].astype(bool)
    
#     # éšæœºé¢œè‰²å¹¶ä¸Šè‰²
#     # color = np.random.randint(0, 255, (3,)).tolist()
#     color = [0, 255, 255]
#     color_overlay[best_mask] = color
#     print(f"å·²ä» JSON è¯»å–å¹¶ä¸Šè‰²: {text}")

# # --- 5. ç»“æœåˆæˆä¸ä¿å­˜ ---
# # final_res = cv2.addWeighted(image_bgr, 0.6, color_overlay, 0.4, 0)
# save_path = os.path.join(output_dir, f"final_result_{img_name}")
# # cv2.imwrite(save_path, final_res)
# cv2.imwrite(save_path, color_overlay)

# print(f"ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼ä¿å­˜è‡³: {save_path}")